{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be7b5da5",
   "metadata": {},
   "source": [
    "# Taller computacional Vectores en $\\mathbb{R}^n$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a130295",
   "metadata": {},
   "source": [
    "Objetivo: Utilizar un ejemplo práctico de procesamiento de texto para visualizar y comprender conceptos fundamentales de álgebra lineal como vectores en $\\mathbb{R}^n$, bases, dimensión e independencia/dependencia lineal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c1b7c3",
   "metadata": {},
   "source": [
    "Ene l procesamiento de texto, en sus inicios se uso la representación de documentos como una bolsa de palabras, donde cada documento se representaba como un vector en $\\mathbb{R}^n$ y cada palabra como una dimensión. En este taller, utilizaremos un conjunto de documentos para ilustrar estos conceptos.\n",
    "\n",
    "\n",
    "Para realizar esto a cada documento se le hace un preprocesamiento, que consiste en:\n",
    "\n",
    "1. **Tokenización**: Separar el texto en palabras o tokens.\n",
    "2. **Lematización**: Reducir las palabras a su forma base o lema.\n",
    "3. **Eliminación de stopwords**: Quitar palabras comunes que no aportan significado (como \"y\", \"el\", \"de\").\n",
    "4. **Vectorización**: Representar cada documento como un vector en $\\mathbb{R}^n$ donde $n$ es el número de palabras únicas en el conjunto de documentos.\n",
    "5. **Normalización**: Escalar los vectores para que tengan una longitud de 1 (opcional).\n",
    "\n",
    "## Ejemplo práctico\n",
    "\n",
    "\n",
    "Supongamos que nuestro documento es el siguiente:\n",
    "\n",
    "\"la casa es grande y la casa es azul\"\n",
    "\n",
    "### Paso 1: Tokenización\n",
    "\n",
    "En la tokenización, separamos el texto en palabras. En este caso, obtenemos:\n",
    "\n",
    "```\n",
    "[\"la\", \"casa\", \"es\", \"grande\", \"y\", \"la\", \"casa\", \"es\", \"azul\"]\n",
    "```\n",
    "### Paso 2: Lematización\n",
    "La lematización consiste en reducir las palabras a su forma base. En este caso, podemos obtener:\n",
    "\n",
    "```\n",
    "[\"la\", \"casa\", \"ser\", \"grande\", \"y\", \"la\", \"casa\", \"ser\", \"azul\"]\n",
    "```\n",
    "### Paso 3: Eliminación de stopwords\n",
    "En este paso, eliminamos las palabras que no aportan significado. En este caso, eliminamos \"la\", \"y\" y \"es\". Obtenemos:\n",
    "\n",
    "```\n",
    "[\"casa\", \"grande\", \"casa\", \"azul\"]\n",
    "```\n",
    "### Paso 4: Vectorización\n",
    "Ahora, representamos cada documento como un vector en $\\mathbb{R}^n$. Para esto, creamos un vocabulario con las palabras únicas del documento. En este caso, el vocabulario es:\n",
    "\n",
    "```\n",
    "[\"casa\", \"grande\", \"azul\"]\n",
    "```\n",
    "Ahora, representamos el documento como un vector en $\\mathbb{R}^3$ (ya que tenemos 3 palabras únicas):\n",
    "\n",
    "```\n",
    "[2, 1, 1]\n",
    "```\n",
    "### Paso 5: Normalización\n",
    "Finalmente, normalizamos el vector para que tenga una longitud de 1. La longitud del vector es:\n",
    "$$\n",
    "\\sqrt{2^2 + 1^2 + 1^2} = \\sqrt{4 + 1 + 1} = \\sqrt{6}\n",
    "$$\n",
    "Por lo tanto, el vector normalizado es:\n",
    "$$\n",
    "\\left[\\frac{2}{\\sqrt{6}}, \\frac{1}{\\sqrt{6}}, \\frac{1}{\\sqrt{6}}\\right]\n",
    "$$\n",
    "\n",
    "## Ejemplo práctico en Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "140fa1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para realizar este este ejercicio usaremos algunas librerías de Python\n",
    "# que nos ayudarán a realizar la manipulación de datos y la visualización\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ba3766",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Textos del ejemplo \n",
    "\n",
    "texts = [\n",
    "    \"El perro corre\",                        # Texto 1\n",
    "    \"El perro corre en el parque\",           # Texto 2\n",
    "    \"El gato duerme en la casa tranquila\",  # Texto 3\n",
    "    \"El gato duerme en la casa\",             # Texto 4\n",
    "    \"Los estudiantes estudian álgebra lineal\" # Texto 5\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4e6084e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Preprocesamiento\n",
    "\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "# Generar las Stop words\n",
    "# En este caso, las stop words son palabras comunes que no aportan mucho significado\n",
    "stop_words = {\"el\", \"la\", \"los\", \"las\", \"en\", \"y\", \"de\", \"a\", \"es\", \"una\", \"un\", \"que\"}\n",
    "\n",
    "# Tokenizar y eliminar stop words\n",
    "processed = [\n",
    "    [t for t in tokenizer.tokenize(txt.lower()) if t not in stop_words]\n",
    "    for txt in texts\n",
    "]\n",
    "\n",
    "# Construir vocabulario\n",
    "vocab = sorted({word for tokens in processed for word in tokens})\n",
    "\n",
    "# Construir matriz término-documento (filas=vocab, columnas=textos)\n",
    "term_doc = np.array([[tokens.count(w) for tokens in processed] for w in vocab])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b5f2950",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['casa',\n",
       " 'corre',\n",
       " 'duerme',\n",
       " 'estudian',\n",
       " 'estudiantes',\n",
       " 'gato',\n",
       " 'hay',\n",
       " 'lineal',\n",
       " 'parque',\n",
       " 'perro',\n",
       " 'tranquila',\n",
       " 'álgebra']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38628c26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1, 1, 0, 1],\n",
       "       [1, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 1, 0, 0],\n",
       "       [0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 1, 1, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1, 0],\n",
       "       [0, 1, 0, 0, 0, 0],\n",
       "       [1, 1, 0, 0, 0, 1],\n",
       "       [0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 1, 0]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "term_doc # Matriz término-documento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c93c0236",
   "metadata": {},
   "source": [
    "**Nots** Recuerda que una matriz \n",
    "$$A=\\begin{bmatrix}\n",
    "1 & 2 & 3 \\\\\n",
    "4 & 5 & 6 \\\\\n",
    "7 & 8 & 9\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "se puede representar en Python como un array de numpy\n",
    "```python\n",
    "import numpy as np\n",
    "A = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "```\n",
    "y si queremos acceder a la columna $2$\n",
    "```python\n",
    "A[:, 1]\n",
    "```\n",
    "y si queremos acceder a la fila $2$\n",
    "```python\n",
    "A[1, :]\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d849b81b",
   "metadata": {},
   "source": [
    "Note que aquí la primera columna de la matriz indica indica la frecuencia de la palabra que aparece en el texto 1, la segunda columna la frecuencia de la palabra que aparece en el texto 2 y así sucesivamente. \n",
    "\n",
    "**Ejercicio 1**: Las columnas de esta matriz son linealmente independientes. ¿Por qué? ¿Qué significa esto en el contexto de la representación de documentos como vectores en $\\mathbb{R}^n$? ¿Cual es la dimensión del espacio generado por las columnas de la matriz?\n",
    "\n",
    "\n",
    "En algebra lineal computacional se acostumbra a trabajar con vectores normalizados esto es porque se busca que la longitud de los vectores sea 1. Lo cual hace que se disminuya los errores de redondeo y se pueda trabajar con una mayor precisión.\n",
    "\n",
    "**Ejercicio 2**: Normalice los vectores de la matriz anterior y genere una nueva matriz con los vectores normalizados. Recuerde que la normalización de un vector $v$ se hace dividiendo cada componente del vector por la longitud del vector. La longitud de un vector $v$ en $\\mathbb{R}^n$ en 'python' se puede calcular como:\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "v = np.array([2, 1, 1])\n",
    "longitud = np.linalg.norm(v)\n",
    "v_normalizado = v / longitud\n",
    "print(v_normalizado)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed5f141",
   "metadata": {},
   "source": [
    "## Coseno  entre vectores \n",
    "\n",
    "El coseno entre dos vectores $u$ y $v$ en $\\mathbb{R}^n$ se puede calcular utilizando el producto punto y la longitud de los vectores. La fórmula es:\n",
    "\n",
    "$$\n",
    "\\cos(\\theta) = \\frac{u \\cdot v}{||u|| \\cdot ||v||}\n",
    "$$\n",
    "\n",
    "Donde $u \\cdot v$ es el producto punto de los vectores $u$ y $v$, y $||u||$ y $||v||$ son las longitudes de los vectores $u$ y $v$, respectivamente.\n",
    "El ángulo $\\theta$ se puede obtener utilizando la función `np.arccos` de NumPy, que devuelve el ángulo en radianes. Para convertirlo a grados, se puede usar la función `np.degrees`.\n",
    "\n",
    "**Ejercicio 3**: Calcule el coseno entre cada uno de los vectores del ejercicio 2. Lea atentamente las frases y el resultado que obtiene. ¿Qué relación existe entre el coseno de los vectores y el significado de cada uno de los documentos? **Nota** Recuerde que el valor del coseno entre dos vectores es un número entre -1 y 1. Un valor de 1 indica que los vectores son paralelos y apuntan en la misma dirección, un valor de -1 indica que son paralelos pero apuntan en direcciones opuestas, y un valor de 0 indica que son ortogonales (perpendiculares) entre sí.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3642dc46",
   "metadata": {},
   "source": [
    "**Ejercicio 4** ¿Qué conjunto forma la base de este espacio vectorial de textos? Si añadiéramos una nueva frase como \"La inteligencia artificial aprende rápido\", ¿cómo cambiaría la base y la dimensión del espacio vectorial?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6341f9a1",
   "metadata": {},
   "source": [
    "**Ejercicio 5** Inventa una frase que pueda ser producto de la combinacion lineal unicamente de la tercera y cuarta columna de la matriz generada en el ejercicio 2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02d65af",
   "metadata": {},
   "source": [
    "Aunque en la actualidad esta técnica de representación de documentos ha sido reemplazada por técnicas más avanzadas como TF-IDF y Word Embeddings, sigue siendo una buena forma de entender los conceptos fundamentales de álgebra lineal y su aplicación en el procesamiento de texto.\n",
    "## Referencias\n",
    "- Albright, S. C., Winston, W. L., & Zapp, A. (2011). Data analysis and decision making (4th ed.). Cengage Learning.\n",
    "- Bishop, C. M. (2006). Pattern recognition and machine learning. Springer.\n",
    "- Goodfellow, I., Bengio, Y., & Courville, A. (2016). Deep learning. MIT Press."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c523e41",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cbdbfbaf",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2dd127cf",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "class",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
